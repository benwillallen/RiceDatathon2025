{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "0nLdmV8Cjb3Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "# torhc dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#import summary for models\n",
        "from torchsummary import summary\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "ZHmU5aNnjb3R"
      },
      "outputs": [],
      "source": [
        "all_data = pd.read_csv(\"Train_and_Validate_EEG.csv\", index_col=0).drop(\"Unnamed: 122\",axis=1)\n",
        "data = all_data.drop(['sex','eeg.date','education','specific.disorder'], axis=1).dropna(axis=0)\n",
        "\n",
        "# Encode disorders\n",
        "encoder = OrdinalEncoder()\n",
        "data[['main.disorder']] = encoder.fit_transform(data[['main.disorder']])\n",
        "\n",
        "X = data.drop(['main.disorder'], axis=1).dropna(axis=0)\n",
        "y = data['main.disorder']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "-S73qwxjjb3S"
      },
      "outputs": [],
      "source": [
        "bands = ['gamma', 'highbeta', 'beta', 'alpha', 'theta', 'delta']\n",
        "bands2 = ['F.gamma', 'E.highbeta', 'D.beta', 'C.alpha', 'B.theta', 'A.delta']\n",
        "\n",
        "# Separate column names based on whether they are PSD or coherence\n",
        "AB_per_band = {}\n",
        "AB_cols = []\n",
        "COH_per_band = {}\n",
        "COH_cols = []\n",
        "\n",
        "for band in bands:\n",
        "    AB_per_band[band] = []\n",
        "    COH_per_band[band] = []\n",
        "\n",
        "for col_name in X_train.drop(['age','IQ'], axis=1).columns:\n",
        "    col_split = col_name.split('.')\n",
        "    if col_split[0] == 'AB':\n",
        "        AB_per_band[col_split[2]].append(col_name)\n",
        "        AB_cols.append(col_name)\n",
        "    else:\n",
        "        COH_per_band[col_split[2]].append(col_name)\n",
        "        COH_cols.append(col_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu4oRNRujb3S",
        "outputId": "571e8aa4-5d10-4931-c17b-36a8995013f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# Get all electrode names\n",
        "electrodes = set()\n",
        "for col in COH_cols:\n",
        "    col_split = col.split('.')\n",
        "    # elec1 = col_split[4]\n",
        "    electrodes.add(col_split[3]+'.'+col_split[4])\n",
        "    # elec2 = col_split[6]\n",
        "    electrodes.add(col_split[5]+'.'+col_split[6])\n",
        "\n",
        "electrodes = list(electrodes)\n",
        "len(electrodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFzM7UHCjb3S"
      },
      "source": [
        "## data preprocessing\n",
        "coherence data shape = [num individuals, frequency bands, electrodes, electrodes]\n",
        "PSD data shape = [num individuals, frequency bands, electrodes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "pGWjHAtUjb3T"
      },
      "outputs": [],
      "source": [
        "num_samples = X_train.shape[0]\n",
        "num_nodes = len(electrodes)\n",
        "num_bands = len(bands)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "C2f8c-XXjb3T"
      },
      "outputs": [],
      "source": [
        "def getCoherenceStacked(coherence):\n",
        "    adj_tensors = []\n",
        "\n",
        "    # for each individual\n",
        "    for i in range(coherence.shape[0]):\n",
        "        indiv_tensors = []\n",
        "\n",
        "        # for each band\n",
        "        for band_idx in range(len(bands2)):\n",
        "            # adjacency matrix electrodes x electrodes\n",
        "            adj_matrix = np.zeros([len(electrodes),len(electrodes)])\n",
        "\n",
        "            for elec1 in range(len(electrodes)):\n",
        "                for elec2 in range(elec1+1, len(electrodes)):\n",
        "                    col_name = 'COH.'+bands2[band_idx]+'.'+electrodes[elec1]+'.'+electrodes[elec2]\n",
        "                    if col_name in coherence.columns:\n",
        "                        adj_matrix[elec1][elec2] = coherence.iloc[i,:][col_name] #individual's row, then get value\n",
        "                    else:\n",
        "                        col_name = 'COH.'+bands2[band_idx]+'.'+electrodes[elec2]+'.'+electrodes[elec1]\n",
        "                        adj_matrix[elec1][elec2] = coherence.iloc[i,:][col_name] #individual's row, then get value\n",
        "            indiv_tensors.append(torch.from_numpy(adj_matrix).fill_diagonal_(1.0))\n",
        "\n",
        "        adj_tensors.append(torch.stack(indiv_tensors))\n",
        "\n",
        "    adj_matrices = torch.stack(adj_tensors)\n",
        "    # print(adj_matrices.shape)\n",
        "    adj_matrices = (adj_matrices + adj_matrices.transpose(2, 3)) / 2  # Ensure symmetry\n",
        "    print(adj_matrices.shape)\n",
        "    return adj_matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "1JhFap70jb3T"
      },
      "outputs": [],
      "source": [
        "def getPSDStacked(psd):\n",
        "    psd_tensors = []\n",
        "    # for each individual\n",
        "    for i in range(psd.shape[0]):\n",
        "        psd_mat = np.zeros([len(electrodes),len(bands2)])\n",
        "\n",
        "        # for each band\n",
        "        for band_idx in range(len(bands2)):\n",
        "            for elec1 in range(len(electrodes)):\n",
        "                col_name = 'AB.'+bands2[band_idx]+'.'+electrodes[elec1]\n",
        "                psd_mat[elec1][band_idx] = psd.iloc[i,:][col_name] #individual's row, then get value\n",
        "\n",
        "        psd_tensors.append(torch.from_numpy(psd_mat))\n",
        "\n",
        "    node_features = torch.stack(psd_tensors)\n",
        "    print(node_features.shape)\n",
        "    return node_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJNAHJVJjb3T",
        "outputId": "8dc2a377-7139-4ff7-aad2-fe0b1cf0da05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([672, 19, 6])\n",
            "torch.Size([168, 19, 6])\n"
          ]
        }
      ],
      "source": [
        "node_features = getPSDStacked(X_train).transpose(1,2)\n",
        "node_features_val = getPSDStacked(X_val).transpose(1,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ttKia4mjb3T"
      },
      "outputs": [],
      "source": [
        "adj_matrices = getCoherenceStacked(X_train)\n",
        "adj_matrices_val = getCoherenceStacked(X_val)\n",
        "\n",
        "# Populating diagonals\n",
        "for i in range(adj_matrices.shape[2]):\n",
        "  adj_matrices[:,:,i,i] = node_features[:,:,i]\n",
        "  adj_matrices_val[:,:,i,i] = node_features_val[:,:,i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P93BsSG8jb3U"
      },
      "outputs": [],
      "source": [
        "# create data loaders from adj_matrices and node_features\n",
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, adj_matrices, node_features, labels):\n",
        "        self.adj_matrices = torch.tensor(adj_matrices, dtype=torch.float32)\n",
        "        self.node_features = torch.tensor(node_features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels.to_list(), dtype=torch.long)\n",
        "        if len(self.adj_matrices) != len(self.labels):\n",
        "            raise ValueError(\"Adjacency matrices and labels must have the same length: {} != {}\".format(len(self.adj_matrices), len(self.labels)))\n",
        "        if len(self.node_features) != len(self.labels):\n",
        "            raise ValueError(\"Node features and labels must have the same length: {} != {}\".format(len(self.node_features), len(self.labels)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.node_features[idx], self.adj_matrices[idx]), self.labels[idx]\n",
        "\n",
        "print(adj_matrices.shape)\n",
        "train_dataset = EEGDataset(adj_matrices, node_features, y_train)\n",
        "val_dataset = EEGDataset(adj_matrices_val, node_features_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh-Osf7vjb3U"
      },
      "source": [
        "## modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_20-gVdjb3U"
      },
      "outputs": [],
      "source": [
        "class EEGClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.15):\n",
        "        super(EEGClassifier, self).__init__()\n",
        "\n",
        "        # Define convolutional 2d layers\n",
        "\n",
        "        # 1, 19, 19\n",
        "        self.conv1 = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(4, 4))\n",
        "            for _ in range(6)\n",
        "        ])\n",
        "        # 8, 16, 16\n",
        "        self.maxpools1 = nn.ModuleList([nn.MaxPool2d(kernel_size=(2, 2)) for _ in range(6)])\n",
        "        # 8, 8, 8\n",
        "\n",
        "        self.conv2 = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3))\n",
        "            for _ in range(6)\n",
        "        ])\n",
        "        # 16, 6, 6\n",
        "        self.maxpools2 = nn.ModuleList([nn.MaxPool2d(kernel_size=(2, 2)) for _ in range(6)])\n",
        "        self.batchnorms = nn.ModuleList([nn.BatchNorm2d(32) for _ in range(6)])\n",
        "        # 16, 3, 3\n",
        "        self.flatten = nn.Flatten()\n",
        "        # 144\n",
        "        self.coh_linears1 = nn.ModuleList([\n",
        "            nn.Linear(288, 128)\n",
        "            for _ in range(6)\n",
        "        ])\n",
        "        self.coh_linears2 = nn.ModuleList([\n",
        "            nn.Linear(128, 64)\n",
        "            for _ in range(6)\n",
        "        ])\n",
        "        self.psd_linears = nn.ModuleList([\n",
        "            nn.Linear(19, 32)\n",
        "            for _ in range(6)\n",
        "        ])\n",
        "        self.band_linears = nn.ModuleList([\n",
        "            nn.Linear(96, 64)\n",
        "            for _ in range(6)\n",
        "        ])\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64 * 6)\n",
        "\n",
        "        # Define linear layers\n",
        "        self.layer1 = nn.Linear(64 * 6, 128)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "\n",
        "        self.layer2 = nn.Linear(128, 32)\n",
        "\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "\n",
        "        self.layer3 = nn.Linear(32, 7)\n",
        "\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x_psd, x_adj):\n",
        "        # x_psd is the PSD data, 6 x 19 tensor\n",
        "        # x_adj is the adjacency matrix data, 6 x 19 x 19 tensor\n",
        "\n",
        "        # Process psds\n",
        "        x_psds = [None for _ in range(6)]\n",
        "        for i in range(6):\n",
        "            x_psds[i] = self.psd_linears[i](x_psd[:,i])\n",
        "            x_psds[i] = self.gelu(x_psds[i])\n",
        "            x_psds[i] = self.dropout(x_psds[i])\n",
        "\n",
        "        # Process adjacency matrices\n",
        "        x_adjs = [None for _ in range(6)]\n",
        "        for i in range(6):\n",
        "            x_adjs[i] = self.conv1[i](x_adj[:,i].unsqueeze(1))\n",
        "            x_adjs[i] = self.maxpools1[i](x_adjs[i])\n",
        "            x_adjs[i] = self.conv2[i](x_adjs[i])\n",
        "            x_adjs[i] = self.maxpools2[i](x_adjs[i])\n",
        "            x_adjs[i] = self.gelu(x_adjs[i])\n",
        "            x_adjs[i] = self.batchnorms[i](x_adjs[i])\n",
        "            x_adjs[i] = self.flatten(x_adjs[i])\n",
        "            x_adjs[i] = self.coh_linears1[i](x_adjs[i])\n",
        "            x_adjs[i] = self.gelu(x_adjs[i])\n",
        "            x_adjs[i] = self.coh_linears2[i](x_adjs[i])\n",
        "            x_adjs[i] = self.gelu(x_adjs[i])\n",
        "            x_adjs[i] = self.dropout(x_adjs[i])\n",
        "\n",
        "        x_bands = [None for _ in range(6)]\n",
        "        for i in range(6):\n",
        "            x_bands[i] = torch.cat([x_psds[i], x_adjs[i]], axis=1)\n",
        "            x_bands[i] = self.band_linears[i](x_bands[i])\n",
        "            x_bands[i] = self.gelu(x_bands[i])\n",
        "\n",
        "        # Concatenate the two\n",
        "        x = torch.cat(x_bands, axis=1)\n",
        "\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        # Apply more linear layers\n",
        "        x = self.layer1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuX0tgKhjb3U"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = EEGClassifier()\n",
        "# Print the model\n",
        "print(model)\n",
        "# how many parameters?\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "print(pytorch_total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7ONccD5jb3U"
      },
      "outputs": [],
      "source": [
        "# Pass through random data\n",
        "x_psd = torch.randn(2, 6, 19)\n",
        "x_adj = torch.randn(2, 6, 19, 19)\n",
        "output = model(x_psd, x_adj)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7j55WZujb3V"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=0.00004,\n",
        "                       weight_decay=1e-5)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer,\n",
        "                              mode='min',\n",
        "                              factor = 0.1,\n",
        "                              patience = 3,\n",
        "                              min_lr = 1e-5,\n",
        "                              verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISh2zBRgjb3V"
      },
      "outputs": [],
      "source": [
        "print(len(train_dataset))\n",
        "for data in train_loader:\n",
        "    (adj_matrices, node_features), labels = data\n",
        "    print(adj_matrices.shape)\n",
        "    print(node_features.shape)\n",
        "    print(labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNyih7WFjb3V"
      },
      "outputs": [],
      "source": [
        "best_loss = np.inf\n",
        "patience = 20\n",
        "min_delta = 0.01\n",
        "early_stop_counter = 0\n",
        "\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "final_epoch = 0\n",
        "\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # train\n",
        "    model.train()\n",
        "    running_loss = 0.\n",
        "    running_accuracy = 0.\n",
        "\n",
        "    for data in train_loader:\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()  # zero gradients\n",
        "\n",
        "        outputs = model.forward(*inputs)  # input net\n",
        "\n",
        "        labels = labels.long()\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        outputs = F.softmax(outputs, dim=1)\n",
        "        top_p, top_class = outputs.topk(k=1, dim=1)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy = (predicted == labels).float().sum()\n",
        "        running_accuracy += accuracy.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = running_accuracy / len(train_dataset)\n",
        "    train_accs.append(epoch_accuracy)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Acc: {epoch_accuracy:.4f}\")\n",
        "    train_losses.append(epoch_loss)\n",
        "\n",
        "    # val\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_accuracy = 0.0\n",
        "    correct = total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            inputs, labels = data\n",
        "\n",
        "            outputs = model(*inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            accuracy = (predicted == labels).float().mean()\n",
        "            val_accuracy += accuracy.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy /= len(val_loader)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\\n\")\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_accuracy)\n",
        "\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_loss - min_delta:\n",
        "        best_loss = val_loss\n",
        "        early_stop_counter = 0\n",
        "        #best_model_state = model.state_dict()\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "\n",
        "    # if early_stop_counter >= patience:\n",
        "    #     print(f\"Early stopping at epoch {epoch+1}.\")\n",
        "    #     final_epoch = epoch+1\n",
        "    #     #model.load_state_dict(best_model_state)\n",
        "    #     break\n",
        "\n",
        "    scheduler.step(val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b0EgE8Ijb3V"
      },
      "outputs": [],
      "source": [
        "# plot accuracy and loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accs, label='Training accuracy')\n",
        "plt.plot(val_accs, label='Validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1xGKyyKjb3W"
      },
      "outputs": [],
      "source": [
        "max(val_accs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}