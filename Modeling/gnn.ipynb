{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"../Data/Train_and_Validate_EEG.csv\", index_col=0).drop(\"Unnamed: 122\",axis=1)\n",
    "data = all_data.drop(['sex','eeg.date','education','specific.disorder'], axis=1).dropna(axis=0)\n",
    "\n",
    "# Encode disorders\n",
    "encoder = OrdinalEncoder()\n",
    "data[['main.disorder']] = encoder.fit_transform(data[['main.disorder']])\n",
    "\n",
    "X = data.drop(['main.disorder'], axis=1).dropna(axis=0)\n",
    "y = data['main.disorder']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['gamma', 'highbeta', 'beta', 'alpha', 'theta', 'delta']\n",
    "bands2 = ['F.gamma', 'E.highbeta', 'D.beta', 'C.alpha', 'B.theta', 'A.delta']\n",
    "\n",
    "# Separate column names based on whether they are PSD or coherence\n",
    "AB_per_band = {}\n",
    "AB_cols = []\n",
    "COH_per_band = {}\n",
    "COH_cols = []\n",
    "\n",
    "for band in bands:\n",
    "    AB_per_band[band] = []\n",
    "    COH_per_band[band] = []\n",
    "\n",
    "for col_name in X_train.drop(['age','IQ'], axis=1).columns:\n",
    "    col_split = col_name.split('.')\n",
    "    if col_split[0] == 'AB':\n",
    "        AB_per_band[col_split[2]].append(col_name)\n",
    "        AB_cols.append(col_name)\n",
    "    else:\n",
    "        COH_per_band[col_split[2]].append(col_name)\n",
    "        COH_cols.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all electrode names\n",
    "electrodes = set()\n",
    "for col in COH_cols:\n",
    "    col_split = col.split('.')\n",
    "    # elec1 = col_split[4]\n",
    "    electrodes.add(col_split[3]+'.'+col_split[4])\n",
    "    # elec2 = col_split[6]\n",
    "    electrodes.add(col_split[5]+'.'+col_split[6])\n",
    "\n",
    "electrodes = list(electrodes)\n",
    "len(electrodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing\n",
    "coherence data shape = [num individuals, frequency bands, electrodes, electrodes]\n",
    "PSD data shape = [num individuals, frequency bands, electrodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = X_train.shape[0]\n",
    "num_nodes = len(electrodes)\n",
    "num_bands = len(bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoherenceStacked(coherence):\n",
    "    adj_tensors = []\n",
    "\n",
    "    # for each individual\n",
    "    for i in range(coherence.shape[0]):\n",
    "        indiv_tensors = []\n",
    "\n",
    "        # for each band\n",
    "        for band_idx in range(len(bands2)):\n",
    "            # adjacency matrix electrodes x electrodes\n",
    "            adj_matrix = np.zeros([len(electrodes),len(electrodes)])\n",
    "\n",
    "            for elec1 in range(len(electrodes)):\n",
    "                for elec2 in range(elec1+1, len(electrodes)):\n",
    "                    col_name = 'COH.'+bands2[band_idx]+'.'+electrodes[elec1]+'.'+electrodes[elec2]\n",
    "                    if col_name in coherence.columns:\n",
    "                        adj_matrix[elec1][elec2] = coherence.iloc[i,:][col_name] #individual's row, then get value\n",
    "                    else: \n",
    "                        col_name = 'COH.'+bands2[band_idx]+'.'+electrodes[elec2]+'.'+electrodes[elec1]\n",
    "                        adj_matrix[elec1][elec2] = coherence.iloc[i,:][col_name] #individual's row, then get value\n",
    "            indiv_tensors.append(torch.from_numpy(adj_matrix).fill_diagonal_(1.0))\n",
    "\n",
    "        adj_tensors.append(torch.stack(indiv_tensors))\n",
    "    \n",
    "    adj_matrices = torch.stack(adj_tensors)\n",
    "    # print(adj_matrices.shape)\n",
    "    adj_matrices = (adj_matrices + adj_matrices.transpose(2, 3)) / 2  # Ensure symmetry\n",
    "    print(adj_matrices.shape)\n",
    "    return adj_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPSDStacked(psd):\n",
    "    psd_tensors = []\n",
    "    # for each individual\n",
    "    for i in range(psd.shape[0]):\n",
    "        psd_mat = np.zeros([len(electrodes),len(bands2)])\n",
    "\n",
    "        # for each band\n",
    "        for band_idx in range(len(bands2)):\n",
    "            for elec1 in range(len(electrodes)):\n",
    "                col_name = 'AB.'+bands2[band_idx]+'.'+electrodes[elec1]\n",
    "                psd_mat[elec1][band_idx] = psd.iloc[i,:][col_name] #individual's row, then get value\n",
    "            \n",
    "        psd_tensors.append(torch.from_numpy(psd_mat))\n",
    "\n",
    "    node_features = torch.stack(psd_tensors)\n",
    "    print(node_features.shape)\n",
    "    return node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([672, 6, 19, 19])\n"
     ]
    }
   ],
   "source": [
    "adj_matrices = getCoherenceStacked(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([672, 19, 6])\n"
     ]
    }
   ],
   "source": [
    "node_features = getPSDStacked(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 0.0, 6.0, 4.0, 1.0, 5.0, 2.0]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_strs = list(y_train.unique())\n",
    "label_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurenyu/Desktop/Projects/RiceDatathon2025/.venv/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.8395034689751883\n",
      "Epoch 10, Loss: 1.8224248479283045\n",
      "Epoch 20, Loss: 1.8220130763356648\n",
      "Epoch 30, Loss: 1.8212487527302332\n",
      "Epoch 40, Loss: 1.8216022328724937\n",
      "Epoch 50, Loss: 1.8218663249697005\n",
      "Epoch 60, Loss: 1.8218212629121446\n",
      "Epoch 70, Loss: 1.821637371229747\n",
      "Epoch 80, Loss: 1.8216487386870006\n",
      "Epoch 90, Loss: 1.8218793774408006\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Simulated node features for each sample (replace with actual PSD values for each band)\n",
    "node_features = torch.rand(num_samples, num_nodes, num_bands)  # Shape: (800, 20, 6)\n",
    "\n",
    "labels = y_train.reset_index(drop=True)\n",
    "\n",
    "# Prepare the dataset\n",
    "graphs = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    for band_idx in range(num_bands):\n",
    "        # Get the adjacency matrix and node features for the current band and sample\n",
    "        adj_matrix = adj_matrices[i, band_idx]\n",
    "        edge_index = adj_matrix.nonzero(as_tuple=False).T\n",
    "        \n",
    "        # Node features: Extract features for the current band for this sample\n",
    "        node_features_sample = node_features[i, :, band_idx].unsqueeze(1)  # Shape: (20, 1)\n",
    "        \n",
    "        # Create a graph for this band of the sample\n",
    "        graph = Data(x=node_features_sample, \n",
    "                     edge_index=edge_index, \n",
    "                     y=labels[i])  # Same label for all graphs in this sample\n",
    "        \n",
    "        graphs.append(graph)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "train_loader = DataLoader(graphs, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define GNN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Apply GCNConv layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # Global mean pooling to get a graph-level representation\n",
    "        x = global_mean_pool(x, batch)  # Shape: [batch_size, out_channels]\n",
    "        return x\n",
    "\n",
    "# Instantiate model\n",
    "model = GCN(1, 16, len(label_strs))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Batch is a single Batch object containing the batched data\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)  # Model output shape: [batch_size, num_classes]\n",
    "        loss = F.cross_entropy(out, batch.y.long())  # Target labels shape: [batch_size]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.87%\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Store predictions and true labels for evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation during evaluation\n",
    "    for batch in train_loader:  # Use test_loader or validation_loader here instead of train_loader\n",
    "        # Get the model's output\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        \n",
    "        # Convert output to predicted labels (e.g., using argmax for classification)\n",
    "        preds = out.argmax(dim=1)  # Get the class with the highest score\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        all_preds.append(preds.cpu().numpy())  # Convert to numpy for evaluation\n",
    "        all_labels.append(batch.y.cpu().numpy())  # Convert to numpy for evaluation\n",
    "\n",
    "# Flatten the lists\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
